{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementando nosso sistema de recomendação em Python usando Gradiente Descendente Estocástico (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD e ALS são dois algoritmos amplamente utilizados para fatorar a matriz de scores (usuário x item) em duas matrizes de dimensões menores, com o benefício de fazer as atualizações do modelo mais fáceis.\n",
    "\n",
    "*Recapitulando algumas coisas*:\n",
    "- **Filtragem Colaborativa** tem como principal vantagem o fato de ser capaz de recomendar itens complexos sem nenhum conhecimento anterior do item.\n",
    "- **Baseados em Memória** usam a **similaridade** entre itens ou usuários, ex. usando a similaridade de cossenos.  \n",
    "- **Baseados em Modelos** usam fatoração de matrizes.\n",
    "\n",
    " *O objetivo principal do algoritmo de fatoração de matrizes é modelar os ratings preditos através da minimização do erro quadrático relativo à matriz de fatores latentes de usuário $P$ e a matriz de fatores latentes de itens $Q$, sobre o conjunto de ratings reais:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?\\underset{Q*&space;,&space;P*}{min}\\sum_{(u,i)\\epsilon&space;K&space;}(r_{ui}-P_u^TQ_i)^2&plus;\\lambda(\\left&space;\\|&space;Q_i&space;\\right&space;\\|^2&space;&plus;&space;\\left&space;\\|&space;P_u&space;\\right&space;\\|^2)$&space;&space;$(1)\" title=\"\\underset{q* , p*}{min}\\sum_{(u,i)\\epsilon K }(r_{ui}-q_i^Tp_u)^2+\\lambda(\\left \\| q_i \\right \\|^2 + \\left \\| p_u \\right \\|^2)\" />\n",
    "\n",
    "Onde $K$ é um conjunto de pares $(u,i)$ tal que o rating é conhecido no conjunto de treino: por exemplo, $r_{ui}$ é o rating do item $i$ dado pelo usuário $u$ no conjunto de treino, e $\\lambda$ é o parâmetro de regularização para evitar overfiting. O erro quadrático regularizado é a **função de perda** que você almeja minimizar. Depois de estimados $P$ e $Q$ através da minimização do erro quadrático, é possível prever os ratings desconhecidos pelo produto escalar dos fatores latentes dos usuários e dos itens.\n",
    "\n",
    "O **gradiente descendente estocástico (SGD)** ou **método dos mínimos quadrados alternados (ALS)** pode ser aplicado para minimizar a função de perda. Ambos *SGD* e *ALS* podem ser usados para aprendizagem em tempo real, ou seja, atualizar o modelo de maneira incremental a cada vez que um novo rating é registrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui será utilizado o dataset MovieLens, onde você deve adicionar os arquivos descompactados do dataset em sua pasta de trabalho do Jupyter Notebook. O dataset pode ser baixado [aqui](http://files.grouplens.org/datasets/movielens/ml-100k.zip).\n",
    "Primeiro, leia o arquivo **u.data** que contém o dataset completo. Uma descrição rápida do dataset pode ser encontrada [aqui](http://files.grouplens.org/datasets/movielens/ml-100k-README.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users = 943 | Number of movies = 1682\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "header = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('./ml-100k/u.data', sep='\\t', names=header)\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print ('Number of users = ' + str(n_users) + ' | Number of movies = ' + str(n_items))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Você pode usar a biblioteca do [`scikit-learn`](http://scikit-learn.org/stable/) para dividir o dataset em duas porções de treino e teste. \n",
    "Ela mistura e divide os dados em dois datasets de acordo com a percentagem de exemplos de teste (``test_size``), que nesse caso é 0.25. O próximo passo será criar a matriz de ratings. Como teremos dados de treino e teste será necessário a criação de duas matrizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df,test_size=0.25)\n",
    "\n",
    "train_data = pd.DataFrame(train_data)\n",
    "test_data = pd.DataFrame(test_data)\n",
    "\n",
    "# Create training and test matrix\n",
    "R = np.zeros((n_users, n_items))\n",
    "for line in train_data.itertuples():\n",
    "    R[line[1]-1, line[2]-1] = line[3]  \n",
    "\n",
    "T = np.zeros((n_users, n_items))\n",
    "for line in test_data.itertuples():\n",
    "    T[line[1]-1, line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As matrizes $I$ e $I2$ servirão como um seletor de matrizes, elas separarão os ratings apropriados de acordo com a atualização das equações durante o treino sobre o dataset de treino (usando $I$) e de predição sobre o dataset de teste (usando $I2$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index matrix for training data\n",
    "I = R.copy()\n",
    "I[I > 0] = 1\n",
    "I[I == 0] = 0\n",
    "\n",
    "# Index matrix for test data\n",
    "I2 = T.copy()\n",
    "I2[I2 > 0] = 1\n",
    "I2[I2 == 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradiente Descendente Estocástico com Regularização por Lambda Ponderado (SGD-WR)\n",
    "\n",
    "Ao utilizar Filtragem Colaborativa com Gradiente Descendente Estocástico, é necessário estimar duas matrizes - a matriz de fatores latentes do usuário $P$ e a matriz de fatores latentes dos itens $Q$. Após estimadas $P$ e $Q$, podem ser preditos os ratings desconhecidos através do produto escalar das matrizes de fatores latentes de usuário e item. <img src=\"https://latex.codecogs.com/gif.latex?\\hat&space;r_{ui}=P_u^TQ_i$&space;&space;$(2)\" title=\"\\hat r_{ui}=p_u^Tq_i\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the unknown ratings through the dot product of the latent features for users and items \n",
    "def prediction(P,Q):\n",
    "    return np.dot(P.T,Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definição matemática do gradiente descendente estocástico quando utilizado para minimizar o erro quadrático regularizado (função de perda):\n",
    "\n",
    "Para atualizar $P$ e $Q$, pode-se utilizar o gradiente descendente estocástico onde tu itera sobre cada observação (linha) no conjunto de treino e atualiza $Q$ e $P$ da seguinte maneira:\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?Q_{i&plus;1}&space;=&space;Q_i&space;&plus;&space;\\gamma&space;(e_{ui}\\cdot&space;P_u-\\lambda\\cdot&space;Q_i)$&space;&space;$(3)\" title=\"Q_{i+1} = Q_i + \\gamma (e_{ui}\\cdot P_u-\\lambda\\cdot Q_i)\" />\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?P_{u&plus;1}&space;=&space;P_u&space;&plus;&space;\\gamma&space;(e_{ui}\\cdot&space;Q_i-\\lambda\\cdot&space;P_u)$&space;&space;$(4)\" title=\"P_{u+1} = P_u + \\gamma (e_{ui}\\cdot Q_i-\\lambda\\cdot P_u)\" />\n",
    "\n",
    "onde $\\gamma$ é a taxa de aprendizagem e $\\lambda$ é o parâmetro de regularização. O erro $(e)$ para o elemento $(u,i)$ é a diferença entre o rating predito e o rating real.\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?e_{ui}=r_{ui}-P_u^TQ_i$&space;&space;$(5)\" title=\"e_{ui}=r_{ui}-p_u^Tq_i\" />\n",
    "\n",
    "Iniciamos definindo os parâmetros do algoritmo $\\lambda$ (peso de regularização) e $k$ (dimensionalidade do espaço de fatores latentes), também iniciando as matrizes de fatores latentes $P$ e $Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbda = 0.1 # Regularisation weight\n",
    "k = 20  # Dimensionality of the latent feature space\n",
    "m, n = R.shape  # Number of users and items\n",
    "n_epochs = 100  # Number of epochs\n",
    "gamma=0.01  # Learning rate\n",
    "\n",
    "P = 3 * np.random.rand(k,m) # Latent user feature matrix\n",
    "Q = 3 * np.random.rand(k,n) # Latent movie feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem várias métricas de avaliação, mas uma das mais populares utilizadas para avaliar a acurácia de ratings preditos é o Erro Quadrático Médio (RMSE), que vamos utilizar nesse tutorial:\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?RMSE&space;=\\sqrt{\\frac{1}{N}&space;\\sum&space;(r_i&space;-\\hat{r_i})^2} $&space;&space;$(6)\" title=\"RMSE =\\sqrt{\\frac{1}{N} \\sum (r_i -\\hat{r_i})^2}\" />\n",
    "\n",
    "onde $N$ é o número de observações (linhas), $r_i$ é o rating real para a observação (linha) $i$ e $\\hat{r_i}$ é o rating predito.\n",
    "Como desejamos considerar apenas os ratings preditos que estão presentes nos conjuntos de treino e teste, filtramos todos os outros ratings na matriz de predição usando ``I`` e ``R[R > 0]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the RMSE\n",
    "def rmse(I,R,Q,P):\n",
    "    return np.sqrt(np.sum((I * (R - prediction(P,Q)))**2)/len(R[R > 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora implementaremos o SGD-WR onde utilizaremos as equações ``(3)``, ``(4)``, ``(5)`` definidas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "#Only consider non-zero matrix \n",
    "users,items = R.nonzero()      \n",
    "for epoch in range(n_epochs):\n",
    "    for u, i in zip(users,items):\n",
    "        e = R[u, i] - prediction(P[:,u],Q[:,i])  # Calculate error for gradient\n",
    "        P[:,u] += gamma * ( e * Q[:,i] - lmbda * P[:,u]) # Update latent user feature matrix\n",
    "        Q[:,i] += gamma * ( e * P[:,u] - lmbda * Q[:,i]) # Update latent movie feature matrix\n",
    "    train_rmse = rmse(I,R,Q,P) # Calculate root mean squared error from train dataset\n",
    "    test_rmse = rmse(I2,T,Q,P) # Calculate root mean squared error from test dataset\n",
    "    train_errors.append(train_rmse)\n",
    "    test_errors.append(test_rmse)\n",
    "    \n",
    "    print (\"[Epoch %d/%d] train error: %f, test error: %f\" \\\n",
    "    %(epoch+1, n_epochs, train_rmse, test_rmse))\n",
    "\n",
    "print(\"Algorithm converged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como foram guardados todos os  ``train_errors`` e ``test_errors`` para cada época, podemos plotar as curva de aprendizagem do algoritmo SGD-WR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check performance by plotting train and test errors\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(n_epochs), train_errors, marker='o', label='Training Data');\n",
    "plt.plot(range(n_epochs), test_errors, marker='v', label='Test Data');\n",
    "plt.title('SGD-WR Learning Curve')\n",
    "plt.xlabel('Number of Epochs');\n",
    "plt.ylabel('RMSE');\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo parece se comportar muito bem, com um RMSE relativamente baixo apor convergir. A performance pode ser influenciada através da calibragem dos parâmetros $\\lambda$, $\\gamma$ and $k$.\n",
    "\n",
    "\n",
    "A seguir tu podes comparar o rating real com o rating predito. Para isso, primeiro calcula-se a matriz de rating preditos - para a qual utilizaremos a função ``prediction`` que foi definida anteriormente, e converter a matriz em um dataframe para facilitar o uso. <img src=\"https://latex.codecogs.com/gif.latex?\\hat&space;r_{ui}=P_u^TQ_i$&space;&space;$(2)\" title=\"\\hat r_{ui}=p_u^Tq_i\" /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prediction matrix R_hat (low-rank approximation for R)\n",
    "R = pd.DataFrame(R)\n",
    "R_hat=pd.DataFrame(prediction(P,Q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para se ter uma ideia do que foi atingido, vamos comparar algumas de nossas predições para o usuário ``29`` com seus ratings reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare true ratings of user 17 with predictions\n",
    "ratings = pd.DataFrame(data=R.loc[28,R.loc[28,:] > 0]).head(n=5)\n",
    "ratings['Prediction'] = R_hat.loc[28,R.loc[28,:] > 0]\n",
    "ratings.columns = ['Actual Rating', 'Predicted Rating']\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "- [Koren et al. (2009)](http://citeseer.ist.psu.edu/viewdoc/download;jsessionid=8413B85890576DE006023342D58E8E67?doi=10.1.1.147.8295&rep=rep1&type=pdf) Koren, Y., Bell, R.M., Volinsky, C.: Matrix factorization techniques for recommender systems. IEEE Computer 42(8), 30–37 (2009) 32 Francesco Ricci, Lior Rokach and Bracha Shapira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<strong>Este tutorial foi adaptado a partir do tutorial de Agnes Johannsdottir e Moritz Haller.</strong>\n",
    "\n",
    "Agnes is a master student in Business Analytics at University College London. She studied Management Engineering in Iceland and worked for 2 years as an IT consultant in supply chain. Her main interests lie in using data science methods (especially machine learning) to apply in Retail and Supply Chain businesses.\n",
    "\n",
    "Moritz has spent the past years in industry, working on business intelligence applications with the company he co-founded. He holds a BSc in Computer Science and is currently pursuing an MSc in Computer Science at University College London. His main interests lie in probabilistic modelling and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
